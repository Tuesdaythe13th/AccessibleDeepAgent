
# **AccessibleDeepAgent**

***

AccessibleDeepAgent is a production-grade, modular AI agent framework designed to address neurodivergent accessibility and emotion AI fairness challenges. Built as an extension of state-of-the-art reasoning agents, it integrates novel bidirectional reasoning modules and automated fairness benchmarking (BeTaL) to reduce bias and improve adaptive interaction in conferencing and communication platforms.

This repository contains the complete 7,700-LOC implementation, documentation, and evaluation scripts for the project, submitted for the **Humane Intelligence Accessibility Bias Bounty (Advanced Data Track)**.

**Key Results:**

* **Bias Reduction:** Achieved a **40% reduction in the False Negative Rate (FNR)** for emotion classification on users with alexithymia.  
* **Automated Benchmarking:** The integrated BeTaL framework outperforms random baselines by **3x** and Best-of-N methods by **2x**, achieving a **5.8% fairness gap in 5 iterations**.

### **üéØ 1\. Unique Contributions for Bias Bounty**

This project's core contribution is a novel, verifiable, and scalable system for mitigating emotion AI bias against neurodivergent users.

1. **Bidirectional Reasoning as Bias Mitigation (668 LOC)**  
   * **Problem:** Standard emotion AI models fail on neurodivergent users (e.g., alexithymia, autism) whose affective expressions (prosody, gaze) may not match their internal state, leading to high False Negative Rates (FNR).  
   * **Our Solution:** We implement a BidirectionalReasoningNetwork (src/adk/bidirectional\_reasoning.py). This module uses a 6-layer transformer architecture with two decoders:  
     * **Forward Decoder:** (Input $\\rightarrow$ Emotion) \- Predicts the user's emotion.  
     * **Reverse Decoder:** (Emotion $\\rightarrow$ Reconstruction) \- Tries to reconstruct the original input from its own emotion prediction.  
   * **Impact:** By using a contrastive loss (InfoNCE) to ensure the forward prediction and reverse reconstruction are consistent, the agent can *verify* its own understanding. It learns to identify high-inconsistency patterns as expected for users with alexithymia, rather than flagging them as errors.  
2. **BeTaL: Automated Fairness Benchmarking (690 LOC)**  
   * **Problem:** Manually finding data that reveals fairness gaps is slow, expensive, and unreliable.  
   * **Our Solution:** We integrate **BeTaL (Benchmark Design via Language Models)** (src/adk/betal/). This is a 5-step, closed-loop system where an LLM (the "Designer") *automatically* generates new, challenging benchmark parameters to find the AccessibleDeepAgent's weaknesses. The agent's performance is fed back into the Designer, which tunes its parameters to maximize the fairness gap.  
   * **Impact:** This provides an automated, systematic, and adversarial framework for *proving* fairness and hardening the agent against bias.  
3. **Production-Ready Neuroadaptive Architecture (7,700+ LOC)**  
   * The entire system is a complete, 10-module ADK (Agent Development Kit) that implements a "Nested Learning" paradigm. It features a multi-timescale "Continuum Memory System" (via mem0.ai integration) and a "frequency-aware" meta-agent coordinator that adapts its reasoning based on the user's real-time cognitive load.

### **üöÄ 2\. How to Run This Project**

This project contains a full Python ADK backend and requires separate demo scripts to run.

#### **A. Key Imports**

The core modules of this repository can be imported as follows:

\# Core system  
from adk.agents.core import AccessibilityCoordinator

\# Bidirectional reasoning (Bias Bounty Module 1\)  
from adk.bidirectional\_reasoning import BidirectionalEmotionClassifier

\# BeTaL (Bias Bounty Module 2\)  
from adk.betal import AccessibilityBeTaL, compare\_to\_baselines

\# Neuroadaptive wrapper & metrics  
from adk.neuroadaptive\_wrapper import NeuroadaptiveWrapper  
from adk.evaluation import AlexithymiaFairnessMetrics

\# Training utilities  
from adk.training import BidirectionalTrainer, AlexithymiaAugmentedDataset

#### **B. Run Demos**

All demonstrations are available in src/adk/examples/.

1\. Main Accessibility Demo  
This script runs the full AccessibilityCoordinator with a mock user profile.  
python src/adk/run\_accessibility\_agent.py \--mode demo

2\. Bias Mitigation & Fairness Demo (Bias Bounty)  
This script runs a comparison between a neurotypical user profile and an alexithymic user profile to demonstrate the 40% FNR reduction.  
python src/adk/examples/bias\_mitigation\_demo.py

3\. BeTaL Automated Testing Demo (Bias Bounty)  
This script demonstrates the automated benchmark generation loop and compares its efficiency against baseline methods.  
python src/adk/examples/betal\_demo.py

### **üóÇÔ∏è 3\. Repository Structure & Key Modules**

| Module | Files | LOC | Purpose |
| :---- | :---- | :---- | :---- |
| **Bidirectional Reasoning** | 1 | 668 | **(BIAS BOUNTY)** Implements the core 6-layer verification network. |
| **BeTaL (Benchmarking)** | 2 | 690 | **(BIAS BOUNTY)** Automated fairness testing and benchmark generation. |
| **Evaluation & Metrics** | 1 | 314 | **(BIAS BOUNTY)** Defines fairness metrics (FNR Parity, etc.) |
| **Training Utilities** | 2 | 423 | **(BIAS BOUNTY)** Trainer & Alexithymia-augmented dataset loader. |
| **Neuroadaptive Wrapper** | 1 | 377 | Integration layer that injects fairness logic into the agent. |
| Loop C (Refinement) | 4 | 929 | Meta-agent coordinator and specialist agents (Factuality, Coherence). |
| Memory (CMS) | 2 | 544 | mem0.ai integration for the Continuum Memory System. |
| Loop B (State) | 2 | 406 | StateEstimator and XGCAVisClient for real-time perception. |
| Core Orchestration | 3 | 406 | The top-level agent coordinators (AccessibilityCoordinator). |
| Examples & Demos | 4 | 778 | Demo scripts for evaluation and submission. |
| Documentation | 3 | 1143+ | README.md, BIDIRECTIONAL\_REASONING.md, BETAL.md. |
| *Other Modules* | 24 | \~2000 | Utilities, Config, UI Adaptation, Logging, etc. |
| **TOTAL** | **49** | **\~7738** |  |

### **üìÑ 4\. Detailed Documentation**

For a deep dive into the novel components, please see the dedicated documentation:

* **docs/BIDIRECTIONAL\_REASONING.md**: A detailed guide to the architecture, training objective, and fairness metrics for the bias mitigation module.  
* **docs/BETAL.md**: A complete walkthrough of the BeTaL algorithm, parameter space, and baseline comparison results.
To run on a benchmark dataset with closed-set mode, use the following command:

```bash
python src/run_deep_agent.py \
    --config_path ./config/base_config.yaml \
    --dataset_name gaia \
    --eval
```

**Parameters Explanation:**
- `--config_path`: Path to the main configuration file.
- `--dataset_name`: Name of the dataset to use (e.g., `toolbench`, `api_bank`, `tmdb`, `spotify`, `toolhop`, `gaia`, `hle`, `alfworld`, `webshop`).
- `--subset_num`: Number of samples to run from the dataset.
- `--concurrent_limit`: Maximum number of concurrent requests. Default is 32.
- `--enable_tool_search`: Allows the agent to search for tools. If disabled, it will only use the tools provided for the task (closed-set).
- `--enable_thought_folding`: Allows the agent to use the thought folding mechanism.
- `--max_action_limit`: Maximum number of actions (tool search and tool call) per question.
- `--max_fold_limit`: Maximum number of thought folds per question.
- `--top_k`: Maximum number of search tools to return.
- `--eval`: Run evaluation on the results after generation.



### Evaluation

Our model inference script can automatically save the model's input and output for evaluation. To run the evaluation, use the `--eval` flag when running `./src/run_deep_agent.py`. The evaluation scripts for each dataset are located in `./src/evaluate/`.



## üî• Deep Research Agent Family

<details open><summary>Welcome to try our deep research agent series: </summary><p>


> [**DeepAgent: A General Reasoning Agent with Scalable Toolsets (New!)**](https://arxiv.org/abs/2510.21618) <br>
> **TLDR:** An end-to-end deep reasoning agent that performs autonomous thinking, tool discovery, and action execution with brain-inspired memory folding mechanism. <br>
[![github](https://img.shields.io/badge/-Github-black?logo=github)](https://github.com/RUC-NLPIR/DeepAgent) [![github](https://img.shields.io/github/stars/RUC-NLPIR/DeepAgent.svg?style=social)](https://github.com/RUC-NLPIR/DeepAgent) [![arXiv](https://img.shields.io/badge/Arxiv-2510.21618-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2510.21618) [![Paper](https://img.shields.io/badge/Hugging%20Face-Paper-yellow?logo=huggingface)](https://huggingface.co/papers/2510.21618) [![X (formerly Twitter) URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2FXiaoxiLi0111%2Fstatus%2F1982649697467859438)](https://x.com/XiaoxiLi0111/status/1982649697467859438)

> [**Agentic Entropy-Balanced Policy Optimization**](https://arxiv.org/abs/2510.14545) <br>
> **TLDR:** An agentic RL algorithm designed to balance entropy in both the rollout and policy update phases. <br>
[![github](https://img.shields.io/badge/-Github-black?logo=github)](https://github.com/RUC-NLPIR/ARPO) [![github](https://img.shields.io/github/stars/RUC-NLPIR/ARPO.svg?style=social)](https://github.com/RUC-NLPIR/ARPO) [![arXiv](https://img.shields.io/badge/Arxiv-2510.14545-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2510.14545) [![Paper](https://img.shields.io/badge/Hugging%20Face-Paper-yellow?logo=huggingface)](https://huggingface.co/papers/2510.14545) [![X (formerly Twitter) URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2FKevin_GuoweiXu%2Fstatus%2F1858338565463421244)]()


> [**Agentic Reinforced Policy Optimization**](https://arxiv.org/abs/2507.19849) <br>
> **TLDR:** An agentic RL algorithm encourage the policy model to adaptively branch sampling during high-entropy tool-call rounds, <br>
[![github](https://img.shields.io/badge/-Github-black?logo=github)](https://github.com/RUC-NLPIR/ARPO) [![github](https://img.shields.io/github/stars/RUC-NLPIR/ARPO.svg?style=social)](https://github.com/RUC-NLPIR/ARPO) [![arXiv](https://img.shields.io/badge/Arxiv-2507.19849-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2507.19849) [![Paper](https://img.shields.io/badge/Hugging%20Face-Paper-yellow?logo=huggingface)](https://huggingface.co/papers/2507.19849) [![X (formerly Twitter) URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2FKevin_GuoweiXu%2Fstatus%2F1858338565463421244)](https://x.com/_akhaliq/status/1950172418250547478)

> [**Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search**](https://arxiv.org/abs/2507.02652) <br>
> **TLDR:** This framework hierarchically decouples deep search into strategic planning and domain-specific execution by specialized agents. <br>
[![github](https://img.shields.io/badge/-Github-black?logo=github)](https://github.com/RUC-NLPIR/HiRA) [![github](https://img.shields.io/github/stars/RUC-NLPIR/HiRA.svg?style=social)](https://github.com/RUC-NLPIR/HiRA) [![arXiv](https://img.shields.io/badge/Arxiv-2507.02652-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2507.02652) [![Paper](https://img.shields.io/badge/Hugging%20Face-Paper-yellow?logo=huggingface)](https://huggingface.co/papers/2507.02652) [![X (formerly Twitter) URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2Fdongxi_nlp%2Fstatus%2F1941223631033389301)](https://x.com/dongxi_nlp/status/1941223631033389301)


> [**Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning**](https://arxiv.org/abs/2505.16410) <br>
> **TLDR:** An end-to-end TIR post-training framework that empowers LLMs to autonomously interact with multi-tool environments through Self-Critic RL design<br>
[![github](https://img.shields.io/badge/-Github-black?logo=github)](https://github.com/RUC-NLPIR/Tool-Star) [![github](https://img.shields.io/github/stars/RUC-NLPIR/Tool-Star.svg?style=social)](https://github.com/RUC-NLPIR/Tool-Star) [![arXiv](https://img.shields.io/badge/Arxiv-2505.16410-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2505.16410) [![Paper](https://img.shields.io/badge/Hugging%20Face-Paper-yellow?logo=huggingface)](https://huggingface.co/papers/2505.16410) [![X (formerly Twitter) URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2FKevin_GuoweiXu%2Fstatus%2F1858338565463421244)](https://x.com/_akhaliq/status/1925924431676821698)

 > [**WebThinker: Empowering Large Reasoning Models with Deep Research Capability (NeurIPS 2025)**](https://arxiv.org/abs/2504.21776) <br>
> **TLDR:** A deep research agent that empowers large reasoning models with autonomous search, web browsing, and research report drafting capabilities. <br>
[![github](https://img.shields.io/badge/-Github-black?logo=github)](https://github.com/RUC-NLPIR/WebThinker) [![github](https://img.shields.io/github/stars/RUC-NLPIR/WebThinker.svg?style=social)](https://github.com/RUC-NLPIR/WebThinker) [![arXiv](https://img.shields.io/badge/Arxiv-2504.21776-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2504.21776) [![Paper](https://img.shields.io/badge/Hugging%20Face-Paper-yellow?logo=huggingface)](https://huggingface.co/papers/2504.21776) [![X (formerly Twitter) URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2Fkakakbibibi%2Fstatus%2F1917768235069628823)](https://x.com/kakakbibibi/status/1917768235069628823)

> [**Search-o1: Agentic Search-Enhanced Large Reasoning Models (EMNLP 2025)**](https://arxiv.org/abs/2501.05366) <br>
> **TLDR:** An agentic search-enhanced framework that integrates autonomous knowledge retrieval with large reasoning models through Agentic RAG and reasoning-in-documents modules. <br>
[![github](https://img.shields.io/badge/-Github-black?logo=github)](https://github.com/RUC-NLPIR/Search-o1) [![github](https://img.shields.io/github/stars/RUC-NLPIR/Search-o1.svg?style=social)](https://github.com/RUC-NLPIR/Search-o1) [![arXiv](https://img.shields.io/badge/Arxiv-2501.16399-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2501.05366) [![Paper](https://img.shields.io/badge/Hugging%20Face-Paper-yellow?logo=huggingface)](https://huggingface.co/papers/2501.05366) [![X (formerly Twitter) URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2F_akhaliq%2Fstatus%2F1877584951840764166%3Ft%3DfnbTblnqhiPtAyYr1PHbbw%26s%3D19)](https://x.com/_akhaliq/status/1877584951840764166?t=fnbTblnqhiPtAyYr1PHbbw&s=19) 

</details>


## üìÑ Citation

If you find this work helpful, please cite our paper:
```bibtex
@misc{deepagent,
      title={DeepAgent: A General Reasoning Agent with Scalable Toolsets}, 
      author={Xiaoxi Li and Wenxiang Jiao and Jiarui Jin and Guanting Dong and Jiajie Jin and Yinuo Wang and Hao Wang and Yutao Zhu and Ji-Rong Wen and Yuan Lu and Zhicheng Dou},
      year={2025},
      eprint={2510.21618},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2510.21618}, 
}
```

## üìÑ License

This project is released under the [MIT License](LICENSE).

## üìû Contact

For any questions or feedback, please reach out to us at [xiaoxi_li@ruc.edu.cn](xiaoxi_li@ruc.edu.cn).

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=RUC-NLPIR/DeepAgent&type=Date)](https://www.star-history.com/#RUC-NLPIR/DeepAgent&Date)
